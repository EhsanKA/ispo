{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline ISP Analysis on Colab\n",
        "\n",
        "This notebook runs the baseline In-Silico Perturbation analysis using Geneformer.\n",
        "\n",
        "## Features:\n",
        "- Loads Geneformer model\n",
        "- Processes SciPlex2 perturbation data\n",
        "- Generates embeddings\n",
        "- Evaluates embedding quality (classification + geometry metrics)\n",
        "- Optional wandb tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Import our custom modules\n",
        "from baseline_isp import GeneformerISPOptimizer\n",
        "\n",
        "print(\"Imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set your parameters here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CONFIG = {\n",
        "    'model_name': 'gf-6L-10M-i2048',  # Start with smaller model for Colab\n",
        "    'num_perturbations': 100,  # Adjust based on Colab memory limits\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'use_wandb': False,  # Set to True if you want wandb tracking\n",
        "    'wandb_project': 'ispo-colab',\n",
        "    'output_dir': 'results/baseline'\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the optimizer\n",
        "optimizer = GeneformerISPOptimizer(\n",
        "    model_name=CONFIG['model_name'],\n",
        "    device=CONFIG['device'],\n",
        "    use_wandb=CONFIG['use_wandb'],\n",
        "    wandb_project=CONFIG['wandb_project'],\n",
        "    wandb_run_name=f\"{CONFIG['model_name']}_colab\"\n",
        ")\n",
        "\n",
        "print(f\"Optimizer initialized with model: {CONFIG['model_name']}\")\n",
        "print(f\"   Device: {CONFIG['device']}\")\n",
        "print(f\"   Wandb tracking: {CONFIG['use_wandb']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Geneformer model\n",
        "# This will download model weights if not already cached\n",
        "optimizer.load_model()\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Perturbation Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load SciPlex2 perturbation data\n",
        "# This will download the data if not already present\n",
        "perturbation_data = optimizer.load_perturbation_data(\n",
        "    num_perturbations=CONFIG['num_perturbations']\n",
        ")\n",
        "\n",
        "print(f\"Data loaded: {perturbation_data.shape}\")\n",
        "print(f\"   Perturbation types: {perturbation_data.obs['perturbation'].value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Baseline Inference\n",
        "\n",
        "This will:\n",
        "1. Process the data\n",
        "2. Generate embeddings\n",
        "3. Evaluate embedding quality\n",
        "4. Track performance metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run baseline inference with evaluation\n",
        "results = optimizer.run_baseline_inference(\n",
        "    perturbation_data,\n",
        "    output_dir=CONFIG['output_dir']\n",
        ")\n",
        "\n",
        "print(\"Inference completed!\")\n",
        "print(f\"   Embeddings shape: {results['embeddings'].shape}\")\n",
        "print(f\"   Total time: {results['performance_metrics']['total_time_seconds']:.2f}s\")\n",
        "print(f\"   Throughput: {CONFIG['num_perturbations'] / results['performance_metrics']['total_time_seconds']:.2f} samples/s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display performance metrics\n",
        "print(\"=\" * 60)\n",
        "print(\"PERFORMANCE METRICS\")\n",
        "print(\"=\" * 60)\n",
        "perf_metrics = results['performance_metrics']\n",
        "for key, value in perf_metrics.items():\n",
        "    if isinstance(value, (int, float)):\n",
        "        print(f\"{key:30s}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"{key:30s}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EVALUATION METRICS (Classification)\")\n",
        "print(\"=\" * 60)\n",
        "if results['evaluation_metrics']:\n",
        "    eval_metrics = results['evaluation_metrics']\n",
        "    for key, value in eval_metrics.items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            print(f\"{key:30s}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"{key:30s}: {value}\")\n",
        "else:\n",
        "    print(\"No evaluation metrics available\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"GEOMETRY METRICS (Clustering & Separation)\")\n",
        "print(\"=\" * 60)\n",
        "if results['geometry_metrics']:\n",
        "    geom_metrics = results['geometry_metrics']\n",
        "    for key, value in geom_metrics.items():\n",
        "        if value is not None:\n",
        "            if isinstance(value, (int, float)):\n",
        "                print(f\"{key:30s}: {value:.4f}\")\n",
        "            else:\n",
        "                print(f\"{key:30s}: {value}\")\n",
        "else:\n",
        "    print(\"No geometry metrics available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 5)\n",
        "\n",
        "# Get embeddings and labels\n",
        "embeddings = results['embeddings']\n",
        "labels = perturbation_data.obs['perturbation'].values\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# 1. PCA visualization\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "embeddings_pca = pca.fit_transform(embeddings)\n",
        "\n",
        "unique_labels = np.unique(labels)\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
        "label_to_color = dict(zip(unique_labels, colors))\n",
        "\n",
        "for label in unique_labels:\n",
        "    mask = labels == label\n",
        "    axes[0].scatter(\n",
        "        embeddings_pca[mask, 0],\n",
        "        embeddings_pca[mask, 1],\n",
        "        label=label,\n",
        "        alpha=0.6,\n",
        "        s=20,\n",
        "        c=[label_to_color[label]]\n",
        "    )\n",
        "\n",
        "axes[0].set_title('PCA Visualization of Embeddings', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
        "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
        "axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. UMAP visualization\n",
        "reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
        "embeddings_umap = reducer.fit_transform(embeddings)\n",
        "\n",
        "for label in unique_labels:\n",
        "    mask = labels == label\n",
        "    axes[1].scatter(\n",
        "        embeddings_umap[mask, 0],\n",
        "        embeddings_umap[mask, 1],\n",
        "        label=label,\n",
        "        alpha=0.6,\n",
        "        s=20,\n",
        "        c=[label_to_color[label]]\n",
        "    )\n",
        "\n",
        "axes[1].set_title('UMAP Visualization of Embeddings', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('UMAP 1')\n",
        "axes[1].set_ylabel('UMAP 2')\n",
        "axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Visualizations created!\")\n",
        "print(f\"   PCA explained variance: {pca.explained_variance_ratio_[:2].sum():.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create performance metrics bar chart\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# 1. Resource usage\n",
        "perf_metrics = results['performance_metrics']\n",
        "resource_data = {\n",
        "    'CPU (%)': [perf_metrics.get('avg_cpu_percent', 0), perf_metrics.get('max_cpu_percent', 0)],\n",
        "    'Memory (%)': [perf_metrics.get('avg_memory_percent', 0), perf_metrics.get('max_memory_percent', 0)],\n",
        "}\n",
        "\n",
        "if 'avg_gpu_percent' in perf_metrics:\n",
        "    resource_data['GPU (%)'] = [perf_metrics.get('avg_gpu_percent', 0), perf_metrics.get('max_gpu_percent', 0)]\n",
        "\n",
        "resource_df = pd.DataFrame(resource_data, index=['Average', 'Peak'])\n",
        "resource_df.plot(kind='bar', ax=axes[0], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "axes[0].set_title('Resource Usage', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Usage (%)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 2. Evaluation metrics\n",
        "if results['evaluation_metrics']:\n",
        "    eval_metrics = results['evaluation_metrics']\n",
        "    eval_data = {\n",
        "        'Accuracy': [eval_metrics.get('zero_shot_accuracy', 0)],\n",
        "        'F1 Score': [eval_metrics.get('zero_shot_f1_score', 0)]\n",
        "    }\n",
        "    eval_df = pd.DataFrame(eval_data)\n",
        "    eval_df.plot(kind='bar', ax=axes[1], color=['#9467bd', '#8c564b'], width=0.6)\n",
        "    axes[1].set_title('Classification Performance', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_ylabel('Score')\n",
        "    axes[1].set_ylim(0, 1)\n",
        "    axes[1].set_xticklabels(['Baseline'], rotation=0)\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "else:\n",
        "    axes[1].text(0.5, 0.5, 'No evaluation metrics', \n",
        "                 ha='center', va='center', transform=axes[1].transAxes)\n",
        "    axes[1].set_title('Classification Performance', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results summary\n",
        "optimizer.save_results_summary([results], \"results/baseline_summary.csv\")\n",
        "\n",
        "print(\"Results summary saved to results/baseline_summary.csv\")\n",
        "\n",
        "# Display summary\n",
        "summary_df = pd.read_csv(\"results/baseline_summary.csv\")\n",
        "print(\"\\nSummary DataFrame:\")\n",
        "display(summary_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finish Wandb Run (if enabled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Finish wandb run if it was enabled\n",
        "if CONFIG['use_wandb'] and optimizer.wandb_run is not None:\n",
        "    optimizer.wandb_run.finish()\n",
        "    print(\"✅ Wandb run completed. Check your dashboard!\")\n",
        "else:\n",
        "    print(\"ℹ️ Wandb tracking was not enabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Results (Optional)\n",
        "\n",
        "If you want to download the results files, uncomment and run the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download results files\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create a zip file of results\n",
        "results_dir = CONFIG['output_dir']\n",
        "if os.path.exists(results_dir):\n",
        "    zip_path = 'results_baseline.zip'\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files_list in os.walk(results_dir):\n",
        "            for file in files_list:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zipf.write(file_path, os.path.relpath(file_path, results_dir))\n",
        "    \n",
        "    # Download the zip file\n",
        "    files.download(zip_path)\n",
        "    print(\"✅ Results downloaded!\")\n",
        "else:\n",
        "    print(\"⚠️ Results directory not found\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
