{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compare Multiple Runs on Colab\n",
        "\n",
        "This notebook allows you to compare:\n",
        "- Different models (e.g., gf-6L-10M vs gf-12L-38M)\n",
        "- Different optimization methods (baseline, batching, mixed precision, ONNX, TensorRT)\n",
        "- Different configurations\n",
        "\n",
        "The notebook imports both `GeneformerISPOptimizer` (baseline) and `OptimizedGeneformerISPOptimizer` (with optimizations) from the Python modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from baseline_isp import GeneformerISPOptimizer\n",
        "from optimized_isp import OptimizedGeneformerISPOptimizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "print(\"Imports successful!\")\n",
        "print(\"Available classes:\")\n",
        "print(\"  - GeneformerISPOptimizer (baseline)\")\n",
        "print(\"  - OptimizedGeneformerISPOptimizer (with optimizations)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Options\n",
        "\n",
        "You can compare:\n",
        "1. **Different models** (e.g., gf-6L-10M vs gf-12L-38M)\n",
        "2. **Different optimization methods** (baseline, batching, mixed precision, ONNX, TensorRT)\n",
        "3. **Different batch sizes**\n",
        "\n",
        "Choose your comparison type below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define configurations to compare\n",
        "# You can compare different models OR different optimization methods\n",
        "\n",
        "# Option 1: Compare different models (using baseline method)\n",
        "configurations_models = [\n",
        "    {\n",
        "        'name': 'baseline_gf-6L-10M',\n",
        "        'model_name': 'gf-6L-10M-i2048',\n",
        "        'num_perturbations': 1000,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'use_wandb': False,\n",
        "        'optimizer_class': 'baseline',  # Use baseline optimizer\n",
        "        'method': 'baseline'\n",
        "    },\n",
        "    # Uncomment to add more models:\n",
        "    # {\n",
        "    #     'name': 'baseline_gf-12L-38M',\n",
        "    #     'model_name': 'gf-12L-38M-i4096',\n",
        "    #     'num_perturbations': 1000,\n",
        "    #     'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    #     'use_wandb': False,\n",
        "    #     'optimizer_class': 'baseline',\n",
        "    #     'method': 'baseline'\n",
        "    # },\n",
        "]\n",
        "\n",
        "# Option 2: Compare different optimization methods (same model)\n",
        "configurations_optimizations = [\n",
        "    {\n",
        "        'name': 'baseline',\n",
        "        'model_name': 'gf-6L-10M-i2048',\n",
        "        'num_perturbations': 1000,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'use_wandb': False,\n",
        "        'optimizer_class': 'baseline',\n",
        "        'method': 'baseline',\n",
        "        'batch_size': 10\n",
        "    },\n",
        "    {\n",
        "        'name': 'batching_bs32',\n",
        "        'model_name': 'gf-6L-10M-i2048',\n",
        "        'num_perturbations': 1000,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'use_wandb': False,\n",
        "        'optimizer_class': 'optimized',\n",
        "        'method': 'batching',\n",
        "        'batch_size': 32\n",
        "    },\n",
        "    {\n",
        "        'name': 'mixed_precision',\n",
        "        'model_name': 'gf-6L-10M-i2048',\n",
        "        'num_perturbations': 1000,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'use_wandb': False,\n",
        "        'optimizer_class': 'optimized',\n",
        "        'method': 'mixed_precision',\n",
        "        'batch_size': 32\n",
        "    },\n",
        "    # Uncomment if ONNX is available:\n",
        "    {\n",
        "        'name': 'onnx_runtime',\n",
        "        'model_name': 'gf-6L-10M-i2048',\n",
        "        'num_perturbations': 1000,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'use_wandb': False,\n",
        "        'optimizer_class': 'optimized',\n",
        "        'method': 'onnx',\n",
        "        'batch_size': 32\n",
        "    },\n",
        "]\n",
        "\n",
        "# Choose which comparison to run\n",
        "COMPARE_MODELS = False  # Set to True to compare different models\n",
        "COMPARE_OPTIMIZATIONS = True  # Set to True to compare optimization methods\n",
        "\n",
        "if COMPARE_MODELS:\n",
        "    configurations = configurations_models\n",
        "    print(f\"Comparing different models: {len(configurations)} configurations\")\n",
        "elif COMPARE_OPTIMIZATIONS:\n",
        "    configurations = configurations_optimizations\n",
        "    print(f\"Comparing optimization methods: {len(configurations)} configurations\")\n",
        "else:\n",
        "    configurations = []\n",
        "    print(\"No comparison selected. Set COMPARE_MODELS or COMPARE_OPTIMIZATIONS to True\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run All Configurations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for config in configurations:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running: {config['name']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Initialize optimizer based on configuration\n",
        "    if config.get('optimizer_class') == 'optimized':\n",
        "        optimizer = OptimizedGeneformerISPOptimizer(\n",
        "            model_name=config['model_name'],\n",
        "            device=config['device']\n",
        "        )\n",
        "    else:\n",
        "        optimizer = GeneformerISPOptimizer(\n",
        "            model_name=config['model_name'],\n",
        "            device=config['device'],\n",
        "            use_wandb=config.get('use_wandb', False),\n",
        "            wandb_project='ispo-colab-comparison',\n",
        "            wandb_run_name=config['name']\n",
        "        )\n",
        "    \n",
        "    # Load model\n",
        "    optimizer.load_model()\n",
        "    \n",
        "    # Load data\n",
        "    data = optimizer.load_perturbation_data(num_perturbations=config['num_perturbations'])\n",
        "    \n",
        "    # Run inference based on method\n",
        "    output_dir = f\"results/{config['name']}\"\n",
        "    method = config.get('method', 'baseline')\n",
        "    batch_size = config.get('batch_size', 10)\n",
        "    \n",
        "    if method == 'baseline':\n",
        "        results = optimizer.run_baseline_inference(data, output_dir=output_dir)\n",
        "    elif method == 'batching':\n",
        "        if hasattr(optimizer, 'run_batching_optimized_inference'):\n",
        "            results = optimizer.run_batching_optimized_inference(\n",
        "                data, batch_size=batch_size, output_dir=output_dir\n",
        "            )\n",
        "        else:\n",
        "            print(f\"WARNING: Batching method not available, using baseline\")\n",
        "            results = optimizer.run_baseline_inference(data, output_dir=output_dir)\n",
        "    elif method == 'mixed_precision':\n",
        "        if hasattr(optimizer, 'run_mixed_precision_inference'):\n",
        "            results = optimizer.run_mixed_precision_inference(\n",
        "                data, batch_size=batch_size, output_dir=output_dir\n",
        "            )\n",
        "        else:\n",
        "            print(f\"WARNING: Mixed precision method not available, using baseline\")\n",
        "            results = optimizer.run_baseline_inference(data, output_dir=output_dir)\n",
        "    elif method == 'onnx':\n",
        "        if hasattr(optimizer, 'run_onnx_inference'):\n",
        "            # First export to ONNX if needed\n",
        "            onnx_path = f\"model_{config['name']}.onnx\"\n",
        "            if not os.path.exists(onnx_path):\n",
        "                optimizer.export_to_onnx(onnx_path)\n",
        "            results = optimizer.run_onnx_inference(\n",
        "                data, onnx_path, batch_size=batch_size, output_dir=output_dir\n",
        "            )\n",
        "        else:\n",
        "            print(f\"WARNING: ONNX not available, using baseline\")\n",
        "            results = optimizer.run_baseline_inference(data, output_dir=output_dir)\n",
        "    else:\n",
        "        # Default to baseline\n",
        "        results = optimizer.run_baseline_inference(data, output_dir=output_dir)\n",
        "    \n",
        "    # Add configuration name\n",
        "    results['config_name'] = config['name']\n",
        "    results['method'] = config.get('method', 'baseline')\n",
        "    \n",
        "    all_results.append(results)\n",
        "    \n",
        "    # Finish wandb if used\n",
        "    if config.get('use_wandb') and hasattr(optimizer, 'wandb_run') and optimizer.wandb_run:\n",
        "        optimizer.wandb_run.finish()\n",
        "    \n",
        "    print(f\"Completed: {config['name']}\")\n",
        "\n",
        "print(f\"\\nAll {len(all_results)} configurations completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison summary\n",
        "GeneformerISPOptimizer.save_results_summary(all_results, \"results/comparison_summary.csv\")\n",
        "\n",
        "# Load and display\n",
        "comparison_df = pd.read_csv(\"results/comparison_summary.csv\")\n",
        "print(\"Comparison Summary:\")\n",
        "print(f\"Total methods compared: {len(comparison_df)}\")\n",
        "display(comparison_df)\n",
        "\n",
        "# Show key metrics\n",
        "if len(comparison_df) > 0:\n",
        "    print(\"\\nKey Performance Metrics:\")\n",
        "    if 'throughput_samples_per_sec' in comparison_df.columns:\n",
        "        print(f\"\\nThroughput (samples/second):\")\n",
        "        for idx, row in comparison_df.iterrows():\n",
        "            method = row.get('method', 'unknown')\n",
        "            throughput = row.get('throughput_samples_per_sec', 0)\n",
        "            if pd.notna(throughput):\n",
        "                print(f\"  {method:20s}: {throughput:.2f} samples/s\")\n",
        "    \n",
        "    if 'zero_shot_accuracy' in comparison_df.columns:\n",
        "        print(f\"\\nZero-shot Accuracy:\")\n",
        "        for idx, row in comparison_df.iterrows():\n",
        "            method = row.get('method', 'unknown')\n",
        "            accuracy = row.get('zero_shot_accuracy', 0)\n",
        "            if pd.notna(accuracy):\n",
        "                print(f\"  {method:20s}: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Throughput comparison\n",
        "if 'throughput_samples_per_sec' in comparison_df.columns:\n",
        "    comparison_df.plot(x='method', y='throughput_samples_per_sec', \n",
        "                       kind='bar', ax=axes[0, 0], color='steelblue')\n",
        "    axes[0, 0].set_title('Throughput Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_ylabel('Samples/second')\n",
        "    axes[0, 0].set_xlabel('')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 2. Accuracy comparison\n",
        "if 'zero_shot_accuracy' in comparison_df.columns:\n",
        "    comparison_df.plot(x='method', y='zero_shot_accuracy',\n",
        "                       kind='bar', ax=axes[0, 1], color='coral')\n",
        "    axes[0, 1].set_title('Zero-Shot Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].set_ylim(0, 1)\n",
        "    axes[0, 1].set_xlabel('')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 3. Silhouette score comparison\n",
        "if 'silhouette_score' in comparison_df.columns:\n",
        "    comparison_df.plot(x='method', y='silhouette_score',\n",
        "                       kind='bar', ax=axes[1, 0], color='mediumseagreen')\n",
        "    axes[1, 0].set_title('Silhouette Score Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_ylabel('Silhouette Score')\n",
        "    axes[1, 0].set_xlabel('')\n",
        "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 4. Separation ratio comparison\n",
        "if 'separation_ratio' in comparison_df.columns:\n",
        "    comparison_df.plot(x='method', y='separation_ratio',\n",
        "                       kind='bar', ax=axes[1, 1], color='gold')\n",
        "    axes[1, 1].set_title('Separation Ratio Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].set_ylabel('Separation Ratio')\n",
        "    axes[1, 1].set_xlabel('')\n",
        "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Comparison Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download comparison results\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = 'comparison_results.zip'\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    if os.path.exists('results/comparison_summary.csv'):\n",
        "        zipf.write('results/comparison_summary.csv')\n",
        "    for result in all_results:\n",
        "        config_name = result['config_name']\n",
        "        results_dir = f'results/{config_name}'\n",
        "        if os.path.exists(results_dir):\n",
        "            for root, dirs, files_list in os.walk(results_dir):\n",
        "                for file in files_list:\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    zipf.write(file_path, f'{config_name}/{os.path.relpath(file_path, results_dir)}')\n",
        "\n",
        "files.download(zip_path)\n",
        "print(\"âœ… Comparison results downloaded!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
